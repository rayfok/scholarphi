[
  {
    "text": "Since being able to track several turns is really important, we made this design decision from the beginning, in contrast to most related work where models are only trained and tested on single-turn dialogs. ",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.4457990196078431,
        "top": 0.4369229797979798,
        "width": 0.03466666666666668,
        "height": 0.012578282828282827,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.45201767676767673,
        "width": 0.39256045751633994,
        "height": 0.012578282828282827,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.4671123737373737,
        "width": 0.39255882352941174,
        "height": 0.012578282828282883,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.48220707070707075,
        "width": 0.39256045751633994,
        "height": 0.012578282828282827,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.4973017676767677,
        "width": 0.13005228758169934,
        "height": 0.012578282828282772,
        "page": 1
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "To give attention to different parts of the context while generating responses, Xing et al. ",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.6331143790849674,
        "top": 0.39918560606060605,
        "width": 0.27898529411764705,
        "height": 0.012578282828282883,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.41428030303030305,
        "width": 0.2996486928104575,
        "height": 0.012578282828282827,
        "page": 1
      }
    ],
    "section": "2 Related Work",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "However, these multiturn dialog models do not take into account the turn-taking emotional changes of the dialog.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.7655980392156863,
        "top": 0.44446969696969696,
        "width": 0.1492483660130719,
        "height": 0.012578282828282883,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.45956439393939397,
        "width": 0.39255882352941174,
        "height": 0.012578282828282827,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.4746603535353535,
        "width": 0.21543300653594777,
        "height": 0.012578282828282827,
        "page": 1
      }
    ],
    "section": "2 Related Work",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "contrast to Affect-LM, Asghars neural affect dialog model aims at generating explicit responses given a particular utterance. ",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.08790522875816993,
        "top": 0.11992929292929293,
        "width": 0.3925588235294118,
        "height": 0.012578282828282841,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.1350239898989899,
        "width": 0.3953039215686275,
        "height": 0.012578282828282827,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.1501199494949495,
        "width": 0.03324673202614378,
        "height": 0.012578282828282827,
        "page": 2
      }
    ],
    "section": "2 Related Work",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "However, literature in affective science does not necessarily validate such rules. ",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.33414052287581697,
        "top": 0.22559343434343432,
        "width": 0.14632843137254914,
        "height": 0.012578282828282855,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.24068939393939395,
        "width": 0.39506699346405233,
        "height": 0.0125782828282828,
        "page": 2
      }
    ],
    "section": "2 Related Work",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "As much as these work in the above section inspired our work, our approach in generating affect dialogs is significantly different. ",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.08733660130718955,
        "top": 0.6935366161616161,
        "width": 0.39343954248366014,
        "height": 0.012578282828282994,
        "page": 2
      },
      {
        "left": 0.08730392156862746,
        "top": 0.7086313131313131,
        "width": 0.3959133986928104,
        "height": 0.012578282828282772,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7237260101010101,
        "width": 0.10292973856209152,
        "height": 0.012578282828282772,
        "page": 2
      }
    ],
    "section": "2 Related Work",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "The main idea is to use an internal memory module to capture the emotion dynamics during decoding, and an external memory module to model emotional expressions explicitly by assigning different probability values to emotional words as opposed to regular words. ",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.08741666666666667,
        "top": 0.3614482323232323,
        "width": 0.39580228758169933,
        "height": 0.012578282828282827,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.37654292929292926,
        "width": 0.3925604575163399,
        "height": 0.012578282828282883,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.39163762626262627,
        "width": 0.3929901960784314,
        "height": 0.012578282828282827,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.4067323232323232,
        "width": 0.3925604575163399,
        "height": 0.012578282828282827,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.42182828282828283,
        "width": 0.1886274509803922,
        "height": 0.012578282828282827,
        "page": 2
      }
    ],
    "section": "2 Related Work",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "We trained our model using two different datasets and compared its performance with HRAN as well as the basic seq2seq model by performing both offline and online testings.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.5187532679738561,
        "top": 0.38346590909090905,
        "width": 0.3960947712418301,
        "height": 0.012578282828282827,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.3985606060606061,
        "width": 0.39345261437908496,
        "height": 0.012578282828282827,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.41365530303030307,
        "width": 0.35515359477124175,
        "height": 0.012578282828282827,
        "page": 4
      }
    ],
    "section": "4 Evaluation",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "We used two different dialog corpora to train our model the Cornell Movie Dialogs Corpus [6] and the DailyDialog dataset [20].",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.5187532679738561,
        "top": 0.45926262626262626,
        "width": 0.3951503267973857,
        "height": 0.012578282828282827,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.47435858585858587,
        "width": 0.39256535947712423,
        "height": 0.012578282828282827,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.4894532828282828,
        "width": 0.08141013071895431,
        "height": 0.012578282828282772,
        "page": 4
      }
    ],
    "section": "4 Evaluation 4.1 Datasets",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "We adopted this training pattern because the Cornell dataset is bigger but noisier, while DailyDialog is smaller but more daily-based. ",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.6628954248366014,
        "top": 0.6916477272727273,
        "width": 0.2519542483660131,
        "height": 0.012578282828282772,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7067424242424243,
        "width": 0.39530392156862737,
        "height": 0.012578282828282772,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7218383838383838,
        "width": 0.23862745098039218,
        "height": 0.012578282828282772,
        "page": 4
      }
    ],
    "section": "4 Evaluation 4.1 Datasets",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "However, for our purpose, which is to speak emotionally appropriately and as human-like as possible, we believe this is a good measure. ",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.6878366013071896,
        "top": 0.4864330808080808,
        "width": 0.22425816993464043,
        "height": 0.012578282828282827,
        "page": 5
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5015277777777778,
        "width": 0.392563725490196,
        "height": 0.012578282828282883,
        "page": 5
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5166224747474748,
        "width": 0.2806797385620915,
        "height": 0.012578282828282772,
        "page": 5
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "But such human experiments are sensitive to risk factors if the experiment is not carefully designed. ",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.7509150326797386,
        "top": 0.8142954545454546,
        "width": 0.16393464052287587,
        "height": 0.012578282828282772,
        "page": 5
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8293901515151515,
        "width": 0.39256045751633983,
        "height": 0.012578282828282994,
        "page": 5
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8444848484848485,
        "width": 0.12207352941176464,
        "height": 0.012578282828282772,
        "page": 5
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "However, recent study [22] suggests that it does not align well with human evaluation. ",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.5990604575163399,
        "top": 0.6071919191919192,
        "width": 0.3130310457516341,
        "height": 0.012578282828282772,
        "page": 5
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6222866161616162,
        "width": 0.24988725490196084,
        "height": 0.012578282828282772,
        "page": 5
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "On the contrary, we did not use Finns r score for contextual coherence and emotional appropriateness because it is only reasonable when the observed variance is significantly less than the chance variance [40], which did not apply to these two criteria. ",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.5195343137254902,
        "top": 0.8142954545454546,
        "width": 0.39531862745098034,
        "height": 0.012590909090908986,
        "page": 6
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8293901515151515,
        "width": 0.392563725490196,
        "height": 0.012578282828282994,
        "page": 6
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8444848484848485,
        "width": 0.39298856209150335,
        "height": 0.012578282828282772,
        "page": 6
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8595795454545455,
        "width": 0.39256535947712423,
        "height": 0.012578282828282772,
        "page": 6
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8746755050505051,
        "width": 0.11661764705882349,
        "height": 0.012578282828282772,
        "page": 6
      }
    ],
    "section": "4 Evaluation 4.4 Results",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "We may wonder how HRAN and MEED differ in terms of the distributional representations of their respective vocabularies (words in the language model, and affect words). ",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.772937908496732,
        "top": 0.39163762626262627,
        "width": 0.1397614379084967,
        "height": 0.012578282828282827,
        "page": 7
      },
      {
        "left": 0.5195343137254902,
        "top": 0.4067323232323232,
        "width": 0.39531535947712426,
        "height": 0.012578282828282827,
        "page": 7
      },
      {
        "left": 0.5195343137254902,
        "top": 0.42182828282828283,
        "width": 0.39256045751633983,
        "height": 0.012578282828282827,
        "page": 7
      },
      {
        "left": 0.5195343137254902,
        "top": 0.4369229797979798,
        "width": 0.2321339869281046,
        "height": 0.012578282828282827,
        "page": 7
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "However, for all of the three criteria in human evaluation, HRAN actually outperforms S2S. ",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.8284035947712418,
        "top": 0.30731060606060606,
        "width": 0.08399346405228747,
        "height": 0.012578282828282827,
        "page": 7
      },
      {
        "left": 0.5195343137254902,
        "top": 0.322405303030303,
        "width": 0.39297712418300657,
        "height": 0.012578282828282827,
        "page": 7
      },
      {
        "left": 0.5195343137254902,
        "top": 0.3375,
        "width": 0.1115653594771242,
        "height": 0.012578282828282827,
        "page": 7
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "On the contrary, HRAN poses a question in reply, contradicting the dialog history.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.14611928104575164,
        "top": 0.6305454545454545,
        "width": 0.3361388888888889,
        "height": 0.012578282828282772,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.6456401515151515,
        "width": 0.2130571895424837,
        "height": 0.012578282828282772,
        "page": 8
      }
    ],
    "section": "4.4.1 Case Study",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "On the contrary, the emotion weights in MEED, in the last plot, have a clearer clustering effect, i.e., positive words are mainly grouped on the top-left, while negative words are mainly grouped at the bottom-right. ",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.08790522875816993,
        "top": 0.4103636363636363,
        "width": 0.3925522875816994,
        "height": 0.012578282828282883,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.4254583333333334,
        "width": 0.39256372549019614,
        "height": 0.012578282828282827,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.44055429292929293,
        "width": 0.39256045751633994,
        "height": 0.012578282828282827,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.45564898989898994,
        "width": 0.23660457516339867,
        "height": 0.012578282828282827,
        "page": 8
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "However, the choice of emotion classifier is not strictly limited to LIWC. ",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.3505261437908497,
        "top": 0.8142954545454546,
        "width": 0.12993954248366013,
        "height": 0.012578282828282772,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8293901515151515,
        "width": 0.33854738562091496,
        "height": 0.012578282828282994,
        "page": 8
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "However they are still in an early stage. ",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.7640343137254902,
        "top": 0.789330808080808,
        "width": 0.1480588235294118,
        "height": 0.012578282828282772,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8044267676767677,
        "width": 0.11017320261437913,
        "height": 0.012578282828282772,
        "page": 8
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "But this condition does not gurantee the optimal results until",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.5195343137254902,
        "top": 0.8648055555555556,
        "width": 0.39256045751633983,
        "height": 0.012578282828282772,
        "page": 8
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "However, for DeepMoji, the 64 categories of emojis do not have a clear and exact correspondence with standardized emotion categories, nor to the VAD vectors.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.7111029411764705,
        "top": 0.34998484848484845,
        "width": 0.2013692810457517,
        "height": 0.012578282828282827,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.3650795454545454,
        "width": 0.39530392156862737,
        "height": 0.012578282828282883,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.3801742424242424,
        "width": 0.39256045751633983,
        "height": 0.012578282828282827,
        "page": 8
      },
      {
        "left": 0.5191274509803921,
        "top": 0.39526893939393937,
        "width": 0.051651960784313666,
        "height": 0.012578282828282827,
        "page": 8
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "In this section, we briefly discuss how our framework can incorporate other components, as well as several directions to extend it.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.08790522875816993,
        "top": 0.6922310606060605,
        "width": 0.39256045751633994,
        "height": 0.012578282828282772,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7073257575757576,
        "width": 0.39255392156862745,
        "height": 0.012578282828282772,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7224204545454546,
        "width": 0.07924509803921571,
        "height": 0.012578282828282772,
        "page": 8
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "Our model uses RNNs to encode the input sequences, and GRU cells to capture long-term dependency among different positions in the sequences. ",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.08790522875816993,
        "top": 0.5376830808080808,
        "width": 0.39256045751633994,
        "height": 0.012578282828282772,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.5527790404040404,
        "width": 0.3925604575163399,
        "height": 0.012578282828282772,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.5678737373737374,
        "width": 0.17981862745098043,
        "height": 0.012578282828282883,
        "page": 9
      }
    ],
    "section": "5 Conclusion and Future Work",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "Our main goal is to increase the objectivity of the results and reduce judges mistakes due to out-of-context dialogs they have to evaluate.",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.08790522875816993,
        "top": 0.8595795454545455,
        "width": 0.3925604575163399,
        "height": 0.012578282828282772,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8746755050505051,
        "width": 0.39298202614379085,
        "height": 0.012578282828282772,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.889770202020202,
        "width": 0.11183496732026145,
        "height": 0.012578282828282772,
        "page": 1
      }
    ],
    "section": "1 Introduction",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "In this paper, we describe an end-to-end Multi-turn Emotionally Engaging Dialog model (MEED), capable of recognizing emotions and generating emotionally appropriate and humanlike responses with the ultimate goal of reproducing social behaviors that are habitual in human-human conversations. ",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.46679738562091505,
        "top": 0.3161628787878788,
        "width": 0.013671568627451003,
        "height": 0.012578282828282827,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.3312588383838384,
        "width": 0.3929901960784314,
        "height": 0.012578282828282827,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.34635353535353536,
        "width": 0.3953039215686275,
        "height": 0.012578282828282827,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.3614482323232323,
        "width": 0.3953153594771242,
        "height": 0.012578282828282827,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.37654292929292926,
        "width": 0.39255882352941174,
        "height": 0.012578282828282883,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.39163762626262627,
        "width": 0.39506862745098037,
        "height": 0.012578282828282827,
        "page": 1
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "Most of related work focused on integrating affect information into the transduction vector space using either VAD or LIWC, we aim at modeling and generating the affect exchanges in human dialogs using a dedicated embedding layer. ",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.19458496732026143,
        "top": 0.7237260101010101,
        "width": 0.2858807189542484,
        "height": 0.012578282828282772,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.738820707070707,
        "width": 0.392562091503268,
        "height": 0.012578282828282772,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.753915404040404,
        "width": 0.3925604575163399,
        "height": 0.012578282828282772,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.769010101010101,
        "width": 0.3953039215686274,
        "height": 0.012578282828282772,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7841060606060606,
        "width": 0.09316013071895425,
        "height": 0.012578282828282994,
        "page": 2
      }
    ],
    "section": "2 Related Work",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "We are able to achieve this goal, i.e., capturing the emotion information carried in the context X , in the encoder, thanks to LIWC. ",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.5358137254901961,
        "top": 0.7992007575757576,
        "width": 0.3762875816993463,
        "height": 0.012578282828282772,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8142575757575758,
        "width": 0.39256045751633983,
        "height": 0.012616161616161525,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8293901515151515,
        "width": 0.058419934640522864,
        "height": 0.012578282828282994,
        "page": 3
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "The main objective of the emotion embedding layer is to recognize the affect information in the given utterances so that the model can respond with emotionally appropriate replies. ",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.5190457516339869,
        "top": 0.6935366161616161,
        "width": 0.39304084967320263,
        "height": 0.012578282828282994,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7086313131313131,
        "width": 0.39256209150326793,
        "height": 0.012578282828282772,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7237260101010101,
        "width": 0.39256045751633983,
        "height": 0.012578282828282772,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.738820707070707,
        "width": 0.046616013071895446,
        "height": 0.012578282828282772,
        "page": 3
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "We use the cross-entropy loss as our objective function",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.5187532679738561,
        "top": 0.2950164141414141,
        "width": 0.3666143790849674,
        "height": 0.012578282828282827,
        "page": 4
      }
    ],
    "section": "3 Model 3.3 Decoding",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "However, for our purpose, which is to speak emotionally appropriately and as human-like as possible, we believe this is a good measure. ",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.6878366013071896,
        "top": 0.4864330808080808,
        "width": 0.22425816993464043,
        "height": 0.012578282828282827,
        "page": 5
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5015277777777778,
        "width": 0.392563725490196,
        "height": 0.012578282828282883,
        "page": 5
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5166224747474748,
        "width": 0.2806797385620915,
        "height": 0.012578282828282772,
        "page": 5
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "For our purposes we filtered out only those dialogs where more than a half of utterances have non-neutral emotional labels, resulting in 78 emotionally positive dialogs and 14 emotionally negative dialogs. ",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.22616993464052287,
        "top": 0.4146010101010101,
        "width": 0.25471078431372546,
        "height": 0.012578282828282883,
        "page": 6
      },
      {
        "left": 0.08790522875816993,
        "top": 0.4296957070707071,
        "width": 0.3925604575163399,
        "height": 0.012578282828282827,
        "page": 6
      },
      {
        "left": 0.08790522875816993,
        "top": 0.44479040404040404,
        "width": 0.3929754901960784,
        "height": 0.012578282828282827,
        "page": 6
      },
      {
        "left": 0.08790522875816993,
        "top": 0.459885101010101,
        "width": 0.36512908496732027,
        "height": 0.012578282828282827,
        "page": 6
      }
    ],
    "section": "4.3.1 Human evaluation setup",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "On the contrary, HRAN poses a question in reply, contradicting the dialog history.",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.14611928104575164,
        "top": 0.6305454545454545,
        "width": 0.3361388888888889,
        "height": 0.012578282828282772,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.6456401515151515,
        "width": 0.2130571895424837,
        "height": 0.012578282828282772,
        "page": 8
      }
    ],
    "section": "4.4.1 Case Study",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Recently, a number of researchers begain developing automatic and data-driven evaluation methods [24, 38], with the ultimate goal of replacing human evaluation. ",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.852328431372549,
        "top": 0.7440467171717171,
        "width": 0.061563725490196064,
        "height": 0.012578282828282772,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7591414141414141,
        "width": 0.39256045751633983,
        "height": 0.012578282828282772,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7742361111111111,
        "width": 0.392563725490196,
        "height": 0.012578282828282772,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.789330808080808,
        "width": 0.240421568627451,
        "height": 0.012578282828282772,
        "page": 8
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "capable of recognizing and generating emotionally appropriate responses, which is the first step toward such a goal. ",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.5195343137254902,
        "top": 0.4573055555555555,
        "width": 0.3953039215686275,
        "height": 0.012578282828282883,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.47240025252525253,
        "width": 0.36740686274509804,
        "height": 0.012578282828282827,
        "page": 9
      }
    ],
    "section": "5 Conclusion and Future Work",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "For future directions, we would like to investigate the diversity issue of the responses generated, possibly by extending the mutual information objective function [17] to multi-turn settings. ",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.5195343137254902,
        "top": 0.562969696969697,
        "width": 0.39531699346405236,
        "height": 0.012578282828282772,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5780643939393939,
        "width": 0.39256209150326793,
        "height": 0.012578282828282772,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5931603535353536,
        "width": 0.3925669934640523,
        "height": 0.012578282828282772,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6082550505050505,
        "width": 0.054500000000000104,
        "height": 0.012578282828282772,
        "page": 9
      }
    ],
    "section": "5 Conclusion and Future Work",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "Many application areas show significant benefits of integrating affect information in natural language dialogs. ",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.5195343137254902,
        "top": 0.3119810606060606,
        "width": 0.3953039215686275,
        "height": 0.012578282828282827,
        "page": 0
      },
      {
        "left": 0.5195343137254902,
        "top": 0.3270757575757576,
        "width": 0.32906209150326804,
        "height": 0.012578282828282827,
        "page": 0
      }
    ],
    "section": "1 Introduction",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "Offline experiments show that our model outperforms both seq2seq and HRAN by a significant amount. ",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.2412794117647059,
        "top": 0.6935366161616161,
        "width": 0.2395016339869281,
        "height": 0.012578282828282994,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7086313131313131,
        "width": 0.3925604575163399,
        "height": 0.012578282828282772,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7237260101010101,
        "width": 0.0547516339869281,
        "height": 0.012578282828282772,
        "page": 1
      }
    ],
    "section": "1 Introduction",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "Further experiments with human evaluation show our model produces emotionally more appropriate responses than both baselines, while also improving the language fluency. ",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.1467140522875817,
        "top": 0.7237260101010101,
        "width": 0.3343578431372549,
        "height": 0.012578282828282772,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.738820707070707,
        "width": 0.39256045751633994,
        "height": 0.012578282828282772,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.753915404040404,
        "width": 0.3953104575163399,
        "height": 0.012578282828282772,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.769010101010101,
        "width": 0.03476960784313725,
        "height": 0.012578282828282772,
        "page": 1
      }
    ],
    "section": "1 Introduction",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "See the discussion section for more details on how to do this. ",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.7243251633986928,
        "top": 0.8746755050505051,
        "width": 0.1880718954248365,
        "height": 0.012578282828282772,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.889770202020202,
        "width": 0.20463071895424845,
        "height": 0.012578282828282772,
        "page": 3
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "See Table 1 for the sizes of the training and validation sets. ",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.3594281045751634,
        "top": 0.1501199494949495,
        "width": 0.12103921568627446,
        "height": 0.012578282828282827,
        "page": 5
      },
      {
        "left": 0.08790522875816993,
        "top": 0.16521464646464645,
        "width": 0.2579313725490196,
        "height": 0.012578282828282855,
        "page": 5
      }
    ],
    "section": "4 Evaluation 4.1 Datasets",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "We conducted t -test on the perplexity obtained, and results show significant improvements of MEED over S2S and HRAN on the two validation sets (with p -value < 0 . 05).",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.6071176470588235,
        "top": 0.5934949494949495,
        "width": 0.3067712418300653,
        "height": 0.012590909090908986,
        "page": 6
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6085896464646464,
        "width": 0.39256045751633983,
        "height": 0.012578282828282772,
        "page": 6
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6233459595959596,
        "width": 0.3950473856209151,
        "height": 0.012930555555555445,
        "page": 6
      }
    ],
    "section": "4 Evaluation 4.4 Results",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "If the emotion embedding layer is learning and distinguishing affect states correctly, we will see clear differences in the visualization.",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.6928660130718954,
        "top": 0.7086313131313131,
        "width": 0.2192287581699346,
        "height": 0.012578282828282772,
        "page": 7
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7237260101010101,
        "width": 0.39256045751633983,
        "height": 0.012578282828282772,
        "page": 7
      },
      {
        "left": 0.5195343137254902,
        "top": 0.738820707070707,
        "width": 0.26798039215686276,
        "height": 0.012578282828282772,
        "page": 7
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "For the first two examples, we can see that MEED is able to generate more emotional content (like fun and congratulations) that is appropriate according to the context. ",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.12991339869281046,
        "top": 0.555070707070707,
        "width": 0.35055228758169943,
        "height": 0.012578282828282772,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.5701654040404041,
        "width": 0.39256045751633994,
        "height": 0.012578282828282772,
        "page": 8
      },
      {
        "left": 0.08606699346405229,
        "top": 0.5852613636363636,
        "width": 0.397140522875817,
        "height": 0.012578282828282772,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.6003560606060606,
        "width": 0.02877614379084968,
        "height": 0.012578282828282772,
        "page": 8
      }
    ],
    "section": "4.4.1 Case Study",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "We can observe from the first two plots that positive words (green dots) and negative words (red dots) are scattered around and mixed with each other in the language model weights for HRAN and MEED respectively, which means no emotion information is captured in these weights. ",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.14004248366013072,
        "top": 0.3348888888888889,
        "width": 0.3431781045751634,
        "height": 0.012578282828282827,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.34998484848484845,
        "width": 0.39256045751633994,
        "height": 0.012578282828282827,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.3650795454545454,
        "width": 0.3925604575163399,
        "height": 0.012578282828282883,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.3801742424242424,
        "width": 0.39256045751633994,
        "height": 0.012578282828282827,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.39526893939393937,
        "width": 0.39507352941176477,
        "height": 0.012578282828282827,
        "page": 8
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "[16] found users frustration caused by a computer system can be alleviated by computer-initiated emotional support, by providing feedback on emotional content along with sympathy and empathy. ",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.8436911764705883,
        "top": 0.3421704545454546,
        "width": 0.06841013071895419,
        "height": 0.012578282828282827,
        "page": 0
      },
      {
        "left": 0.5195343137254902,
        "top": 0.35726515151515154,
        "width": 0.3953039215686275,
        "height": 0.012578282828282827,
        "page": 0
      },
      {
        "left": 0.5195343137254902,
        "top": 0.3723598484848485,
        "width": 0.39255228758169936,
        "height": 0.012578282828282827,
        "page": 0
      },
      {
        "left": 0.5195343137254902,
        "top": 0.3874558080808081,
        "width": 0.39256045751633983,
        "height": 0.012578282828282827,
        "page": 0
      },
      {
        "left": 0.5195343137254902,
        "top": 0.40255050505050505,
        "width": 0.06044444444444452,
        "height": 0.012578282828282827,
        "page": 0
      }
    ],
    "section": "1 Introduction",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "[14] developed a customer support neural chatbot, capable of generating dialogs similar to the humans in terms of empathic and passionate tones, potentially serving as proxy customer support agents on social media platforms. ",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.7081013071895425,
        "top": 0.40255050505050505,
        "width": 0.2067516339869282,
        "height": 0.012578282828282827,
        "page": 0
      },
      {
        "left": 0.5195343137254902,
        "top": 0.417645202020202,
        "width": 0.3928758169934641,
        "height": 0.012578282828282883,
        "page": 0
      },
      {
        "left": 0.5195343137254902,
        "top": 0.432739898989899,
        "width": 0.3943529411764706,
        "height": 0.012578282828282827,
        "page": 0
      },
      {
        "left": 0.5195343137254902,
        "top": 0.44783459595959596,
        "width": 0.39256045751633983,
        "height": 0.012578282828282827,
        "page": 0
      },
      {
        "left": 0.5195343137254902,
        "top": 0.4629292929292929,
        "width": 0.15747549019607843,
        "height": 0.012578282828282827,
        "page": 0
      }
    ],
    "section": "1 Introduction",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "In a qualitative study [47], participants expressed an interest in chatbots capable of serving as an attentive listener and providing motivational support, thus fulfilling users emotional needs. ",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.6815261437908496,
        "top": 0.4629292929292929,
        "width": 0.23332026143790852,
        "height": 0.012578282828282827,
        "page": 0
      },
      {
        "left": 0.5195343137254902,
        "top": 0.4780252525252525,
        "width": 0.39256045751633983,
        "height": 0.012578282828282827,
        "page": 0
      },
      {
        "left": 0.5195343137254902,
        "top": 0.49311994949494947,
        "width": 0.39435457516339867,
        "height": 0.012578282828282827,
        "page": 0
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5082146464646464,
        "width": 0.25459477124183005,
        "height": 0.012578282828282883,
        "page": 0
      }
    ],
    "section": "1 Introduction",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "(3) We illustrate a human-evaluation procedure for judging machine produced emotional dialogs. ",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.12816993464052287,
        "top": 0.769010101010101,
        "width": 0.3526111111111111,
        "height": 0.012578282828282772,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7841060606060606,
        "width": 0.306109477124183,
        "height": 0.012578282828282994,
        "page": 1
      }
    ],
    "section": "1 Introduction",
    "prob": 0.5,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "We chose the multi-turn setting because a model suitable for single-turn dialogs cannot effectively track earlier context in multi-turn dialogs, both semantically and emotionally. ",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.08712418300653595,
        "top": 0.4067323232323232,
        "width": 0.3936454248366013,
        "height": 0.012578282828282827,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.42182828282828283,
        "width": 0.39256045751633994,
        "height": 0.012578282828282827,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.4369229797979798,
        "width": 0.353874183006536,
        "height": 0.012578282828282827,
        "page": 1
      }
    ],
    "section": "",
    "prob": 0.5,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "The paper also proposed the affectively diverse beam search during decoding, so that the generated candidate responses are as affectively diverse as possible. ",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.08741666666666667,
        "top": 0.19540404040404039,
        "width": 0.39304084967320263,
        "height": 0.012578282828282855,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.21049873737373737,
        "width": 0.39256535947712423,
        "height": 0.012578282828282827,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.22559343434343432,
        "width": 0.24217483660130718,
        "height": 0.012578282828282855,
        "page": 2
      }
    ],
    "section": "2 Related Work",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "The approach is also completely data-driven, thus absent of hand-crafted rules. ",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.18512254901960784,
        "top": 0.7841060606060606,
        "width": 0.29713725490196075,
        "height": 0.012578282828282994,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7992007575757576,
        "width": 0.21839869281045754,
        "height": 0.012578282828282772,
        "page": 2
      }
    ],
    "section": "2 Related Work",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "because it is a well-established emotion lexical resource, covering the whole English dictionary whereas VAD only contains 13K lemmatized terms.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.5195343137254902,
        "top": 0.11992929292929293,
        "width": 0.39530392156862737,
        "height": 0.012578282828282841,
        "page": 2
      },
      {
        "left": 0.5195343137254902,
        "top": 0.1350239898989899,
        "width": 0.39531045751633986,
        "height": 0.012578282828282827,
        "page": 2
      },
      {
        "left": 0.5195343137254902,
        "top": 0.1501199494949495,
        "width": 0.1879705882352941,
        "height": 0.012578282828282827,
        "page": 2
      }
    ],
    "section": "",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "The utterance-level encoder is a unidirectional RNN with GRU that goes from the last utterance in the context to the first, with its input at each step as the summary of the corresponding utterance, which is obtained by applying a Bahdanau-style attention mechanism [2] on the word-level",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.5190457516339869,
        "top": 0.8293901515151515,
        "width": 0.39304084967320263,
        "height": 0.012578282828282994,
        "page": 2
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8444848484848485,
        "width": 0.39256045751633994,
        "height": 0.012578282828282772,
        "page": 2
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8595795454545455,
        "width": 0.39256045751633983,
        "height": 0.012578282828282772,
        "page": 2
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8746755050505051,
        "width": 0.39256045751633983,
        "height": 0.012578282828282772,
        "page": 2
      },
      {
        "left": 0.5195343137254902,
        "top": 0.889770202020202,
        "width": 0.3925669934640523,
        "height": 0.012578282828282772,
        "page": 2
      }
    ],
    "section": "3 Model 3.1 Hierarchical Attention",
    "prob": 1,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "More specifically, at decoding step t , the summary of utterance x j is a linear combination of h jk , for k = 1 , 2 , . . . , n j ,",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.2012124183006536,
        "top": 0.5275782828282828,
        "width": 0.2792532679738562,
        "height": 0.012590909090909208,
        "page": 3
      },
      {
        "left": 0.08790522875816993,
        "top": 0.542635101010101,
        "width": 0.39286764705882354,
        "height": 0.01386616161616161,
        "page": 3
      },
      {
        "left": 0.08725490196078431,
        "top": 0.5548232323232324,
        "width": 0.10314215686274508,
        "height": 0.016623737373737346,
        "page": 3
      }
    ],
    "section": "3 Model 3.1 Hierarchical Attention",
    "prob": 1,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "We adopted this training pattern because the Cornell dataset is bigger but noisier, while DailyDialog is smaller but more daily-based. ",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.6628954248366014,
        "top": 0.6916477272727273,
        "width": 0.2519542483660131,
        "height": 0.012578282828282772,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7067424242424243,
        "width": 0.39530392156862737,
        "height": 0.012578282828282772,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7218383838383838,
        "width": 0.23862745098039218,
        "height": 0.012578282828282772,
        "page": 4
      }
    ],
    "section": "4 Evaluation 4.1 Datasets",
    "prob": 0.5,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "Thus a lower perplexity score indicates that the model has better capability of predicting the target sentence, i.e., the humans response. ",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.5190457516339869,
        "top": 0.39586363636363636,
        "width": 0.3930571895424837,
        "height": 0.012578282828282827,
        "page": 5
      },
      {
        "left": 0.5195343137254902,
        "top": 0.4109583333333333,
        "width": 0.39256045751633983,
        "height": 0.012578282828282827,
        "page": 5
      },
      {
        "left": 0.5195343137254902,
        "top": 0.4260530303030303,
        "width": 0.1237205882352942,
        "height": 0.012578282828282827,
        "page": 5
      }
    ],
    "section": "",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Some researchers [19, 34, 48] argue that perplexity score is not the ideal measurement because for a given context history, one should allow many responses. ",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.6473169934640524,
        "top": 0.4260530303030303,
        "width": 0.26478431372549016,
        "height": 0.012578282828282827,
        "page": 5
      },
      {
        "left": 0.5195343137254902,
        "top": 0.4411477272727273,
        "width": 0.39287581699346397,
        "height": 0.012578282828282827,
        "page": 5
      },
      {
        "left": 0.5195343137254902,
        "top": 0.4562436868686869,
        "width": 0.3950669934640523,
        "height": 0.012578282828282827,
        "page": 5
      }
    ],
    "section": "",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "However, for our purpose, which is to speak emotionally appropriately and as human-like as possible, we believe this is a good measure. ",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.6878366013071896,
        "top": 0.4864330808080808,
        "width": 0.22425816993464043,
        "height": 0.012578282828282827,
        "page": 5
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5015277777777778,
        "width": 0.392563725490196,
        "height": 0.012578282828282883,
        "page": 5
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5166224747474748,
        "width": 0.2806797385620915,
        "height": 0.012578282828282772,
        "page": 5
      }
    ],
    "section": "",
    "prob": 0.5,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "Here we summarize the configurations and parameters of our experiments:",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.3523545751633987,
        "top": 0.5584267676767677,
        "width": 0.12810457516339874,
        "height": 0.012578282828282772,
        "page": 5
      },
      {
        "left": 0.08790522875816993,
        "top": 0.5735214646464646,
        "width": 0.36265849673202616,
        "height": 0.012578282828282772,
        "page": 5
      }
    ],
    "section": "4 Evaluation 4.2 Baselines and Implementation",
    "prob": 1,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "Therefore, in this paper, we mainly adopt human evaluation, along with perplexity and BLEU score, following the existing work.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.5190457516339869,
        "top": 0.1350239898989899,
        "width": 0.39484150326797385,
        "height": 0.012578282828282827,
        "page": 5
      },
      {
        "left": 0.5195343137254902,
        "top": 0.1501199494949495,
        "width": 0.39256045751633994,
        "height": 0.012578282828282827,
        "page": 5
      },
      {
        "left": 0.5189330065359476,
        "top": 0.16521464646464645,
        "width": 0.0382058823529412,
        "height": 0.012578282828282855,
        "page": 5
      }
    ],
    "section": "4 Evaluation 4.3 Evaluation Metrics",
    "prob": 0.5,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "by randomly sampling the dialogs from the dataset, it may include out-of-context dialogs, causing confusion and ambiguity for human evaluators. ",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.08790522875816993,
        "top": 0.11992929292929293,
        "width": 0.3953039215686274,
        "height": 0.012578282828282841,
        "page": 6
      },
      {
        "left": 0.08790522875816993,
        "top": 0.1350239898989899,
        "width": 0.39531209150326796,
        "height": 0.012578282828282827,
        "page": 6
      },
      {
        "left": 0.08790522875816993,
        "top": 0.1501199494949495,
        "width": 0.1636633986928105,
        "height": 0.012578282828282827,
        "page": 6
      }
    ],
    "section": "4.3.1 Human evaluation setup",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Unbalanced emotional distribution of the test dialogs may also lead to biased conclusions since the chatbots abilities are evaluated on the unrepresentative",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.25511111111111107,
        "top": 0.1501199494949495,
        "width": 0.2253545751633988,
        "height": 0.012578282828282827,
        "page": 6
      },
      {
        "left": 0.08790522875816993,
        "top": 0.16521464646464645,
        "width": 0.39255392156862745,
        "height": 0.012578282828282855,
        "page": 6
      },
      {
        "left": 0.08790522875816993,
        "top": 0.18030934343434343,
        "width": 0.39256372549019614,
        "height": 0.012578282828282827,
        "page": 6
      }
    ],
    "section": "4.3.1 Human evaluation setup",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Table 3, 4 and 5 summarize the human evaluation results on the responses grammatical correctness, contextual coherence, and emotional appropriateness, respectively. ",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.7027826797385621,
        "top": 0.6482512626262625,
        "width": 0.209313725490196,
        "height": 0.012578282828282772,
        "page": 6
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6633459595959597,
        "width": 0.39256045751633994,
        "height": 0.012578282828282772,
        "page": 6
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6784406565656567,
        "width": 0.3953071895424837,
        "height": 0.012578282828282772,
        "page": 6
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6935366161616161,
        "width": 0.13584150326797384,
        "height": 0.012578282828282994,
        "page": 6
      }
    ],
    "section": "4 Evaluation 4.4 Results",
    "prob": 1,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "On the contrary, we did not use Finns r score for contextual coherence and emotional appropriateness because it is only reasonable when the observed variance is significantly less than the chance variance [40], which did not apply to these two criteria. ",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.5195343137254902,
        "top": 0.8142954545454546,
        "width": 0.39531862745098034,
        "height": 0.012590909090908986,
        "page": 6
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8293901515151515,
        "width": 0.392563725490196,
        "height": 0.012578282828282994,
        "page": 6
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8444848484848485,
        "width": 0.39298856209150335,
        "height": 0.012578282828282772,
        "page": 6
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8595795454545455,
        "width": 0.39256535947712423,
        "height": 0.012578282828282772,
        "page": 6
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8746755050505051,
        "width": 0.11661764705882349,
        "height": 0.012578282828282772,
        "page": 6
      }
    ],
    "section": "4 Evaluation 4.4 Results",
    "prob": 0.5,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "Thus the i th row of the weight matrix W i can be regarded as a vector representation of the i th word in the vocabulary. ",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.7595882352941177,
        "top": 0.5878712121212121,
        "width": 0.15250326797385627,
        "height": 0.012590909090909097,
        "page": 7
      },
      {
        "left": 0.5189330065359476,
        "top": 0.6029292929292929,
        "width": 0.3959084967320262,
        "height": 0.013717171717171794,
        "page": 7
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6180618686868686,
        "width": 0.24893464052287584,
        "height": 0.012590909090909097,
        "page": 7
      }
    ],
    "section": "",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "We may wonder how HRAN and MEED differ in terms of the distributional representations of their respective vocabularies (words in the language model, and affect words). ",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.772937908496732,
        "top": 0.39163762626262627,
        "width": 0.1397614379084967,
        "height": 0.012578282828282827,
        "page": 7
      },
      {
        "left": 0.5195343137254902,
        "top": 0.4067323232323232,
        "width": 0.39531535947712426,
        "height": 0.012578282828282827,
        "page": 7
      },
      {
        "left": 0.5195343137254902,
        "top": 0.42182828282828283,
        "width": 0.39256045751633983,
        "height": 0.012578282828282827,
        "page": 7
      },
      {
        "left": 0.5195343137254902,
        "top": 0.4369229797979798,
        "width": 0.2321339869281046,
        "height": 0.012578282828282827,
        "page": 7
      }
    ],
    "section": "",
    "prob": 0.5,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "Based on this, we conclude that perplexity alone is not enough for evaluating a dialog system.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.6351977124183006,
        "top": 0.3375,
        "width": 0.27731372549019606,
        "height": 0.012578282828282827,
        "page": 7
      },
      {
        "left": 0.5195343137254902,
        "top": 0.3525959595959596,
        "width": 0.33838725490196087,
        "height": 0.012578282828282883,
        "page": 7
      }
    ],
    "section": "",
    "prob": 1,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "We adopted this particular training order because we would like our chatbot to talk more like human chit-chats, and the DailyDialog dataset, compared with the bigger Cornell dataset, is more daily-based. ",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.834532679738562,
        "top": 0.4564457070707071,
        "width": 0.07755718954248358,
        "height": 0.012578282828282827,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.47154040404040404,
        "width": 0.3953039215686275,
        "height": 0.012578282828282883,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.48663636363636364,
        "width": 0.39255882352941185,
        "height": 0.012578282828282827,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5017310606060605,
        "width": 0.39256209150326793,
        "height": 0.012578282828282883,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5168257575757575,
        "width": 0.07770751633986928,
        "height": 0.012578282828282772,
        "page": 8
      }
    ],
    "section": "",
    "prob": 0.5,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "Thus, in the future, we plan to train our model on the multi-turn conversations that we have already extracted from the much bigger OpenSubtitles corpus and the EmpatheticDialogues dataset. ",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.5777124183006536,
        "top": 0.5772058080808081,
        "width": 0.33437581699346397,
        "height": 0.012578282828282772,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.592300505050505,
        "width": 0.39256209150326793,
        "height": 0.012578282828282883,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.607395202020202,
        "width": 0.3953071895424838,
        "height": 0.012578282828282772,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.622489898989899,
        "width": 0.15855555555555545,
        "height": 0.012578282828282772,
        "page": 8
      }
    ],
    "section": "",
    "prob": 0.5,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "It could be replaced by other well-established affect recognizer or one that is more appropriate to the target domain. ",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.43053104575163403,
        "top": 0.8293901515151515,
        "width": 0.049926470588235294,
        "height": 0.012578282828282994,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8444848484848485,
        "width": 0.39256045751633994,
        "height": 0.012578282828282772,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8595795454545455,
        "width": 0.30502124183006535,
        "height": 0.012578282828282772,
        "page": 8
      }
    ],
    "section": "",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "For future directions, we would like to investigate the diversity issue of the responses generated, possibly by extending the mutual information objective function [17] to multi-turn settings. ",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.5195343137254902,
        "top": 0.562969696969697,
        "width": 0.39531699346405236,
        "height": 0.012578282828282772,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5780643939393939,
        "width": 0.39256209150326793,
        "height": 0.012578282828282772,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5931603535353536,
        "width": 0.3925669934640523,
        "height": 0.012578282828282772,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6082550505050505,
        "width": 0.054500000000000104,
        "height": 0.012578282828282772,
        "page": 9
      }
    ],
    "section": "5 Conclusion and Future Work",
    "prob": 0.5,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "We thus highly recommend this combination, which is also a common practice in the research community [45, 4850].",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.3569232026143791,
        "top": 0.4573055555555555,
        "width": 0.12628594771241825,
        "height": 0.012578282828282883,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.47240025252525253,
        "width": 0.3925604575163399,
        "height": 0.012578282828282827,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.4874949494949495,
        "width": 0.2600686274509804,
        "height": 0.012578282828282827,
        "page": 9
      }
    ],
    "section": "5 Conclusion and Future Work",
    "prob": 0.5,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "Compared with RNNs, the Transformer can capture better long-term dependency due to the self-attention mechanism, which is free of locality biases, and is more efficient to train because of better parallelization capability. ",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.16179084967320262,
        "top": 0.6282525252525253,
        "width": 0.32141993464052293,
        "height": 0.012578282828282772,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.6433484848484848,
        "width": 0.392562091503268,
        "height": 0.012578282828282883,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.6584431818181817,
        "width": 0.3953071895424837,
        "height": 0.012578282828282772,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.6735378787878789,
        "width": 0.39506699346405233,
        "height": 0.012578282828282772,
        "page": 9
      }
    ],
    "section": "5 Conclusion and Future Work",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "Following the Transformer architecture, researchers found that pre-training language models on huge amounts of data could largely boost the performance of downstream tasks, and published many pre-trained language models such as BERT [7] and RoBERTa [23]. ",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.08790522875816993,
        "top": 0.6886325757575759,
        "width": 0.3925637254901962,
        "height": 0.012578282828282772,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7037272727272726,
        "width": 0.392562091503268,
        "height": 0.012578282828282772,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7188219696969698,
        "width": 0.39435294117647063,
        "height": 0.012578282828282772,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7339179292929293,
        "width": 0.3925604575163399,
        "height": 0.012578282828282772,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7490126262626262,
        "width": 0.18878104575163396,
        "height": 0.012578282828282772,
        "page": 9
      }
    ],
    "section": "5 Conclusion and Future Work",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "Further experiments with human evaluation show our model produces emotionally more appropriate responses than both baselines, while also improving the language fluency. ",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.1467140522875817,
        "top": 0.7237260101010101,
        "width": 0.3343578431372549,
        "height": 0.012578282828282772,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.738820707070707,
        "width": 0.39256045751633994,
        "height": 0.012578282828282772,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.753915404040404,
        "width": 0.3953104575163399,
        "height": 0.012578282828282772,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.769010101010101,
        "width": 0.03476960784313725,
        "height": 0.012578282828282772,
        "page": 1
      }
    ],
    "section": "1 Introduction",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "[34] further trained the seq2seq model with attention mechanism on a self-crawled Weibo (a popular Twitter-like social media website in China) dataset. ",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.8563398692810458,
        "top": 0.2029520202020202,
        "width": 0.058511437908496666,
        "height": 0.012578282828282827,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.2180467171717172,
        "width": 0.39256045751633983,
        "height": 0.012578282828282827,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.23314141414141415,
        "width": 0.39256045751633983,
        "height": 0.012578282828282855,
        "page": 1
      },
      {
        "left": 0.5189330065359476,
        "top": 0.24823611111111113,
        "width": 0.17327450980392156,
        "height": 0.0125782828282828,
        "page": 1
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "To achieve this, we need an encoder to distinguish the affect information in the context, in addition to its semantic meaning. ",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.5690212418300653,
        "top": 0.738820707070707,
        "width": 0.34307352941176483,
        "height": 0.012578282828282772,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.753915404040404,
        "width": 0.39255882352941185,
        "height": 0.012578282828282772,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.769010101010101,
        "width": 0.06012745098039218,
        "height": 0.012578282828282772,
        "page": 3
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "Equally we need a decoder capable of selecting the best and most human-like answers.",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.5834428104575163,
        "top": 0.769010101010101,
        "width": 0.3286519607843138,
        "height": 0.012578282828282772,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7841060606060606,
        "width": 0.23454411764705874,
        "height": 0.012578282828282994,
        "page": 3
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "Further, if a test set for human evaluation is prepared",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.5605196078431373,
        "top": 0.889770202020202,
        "width": 0.3515686274509804,
        "height": 0.012578282828282772,
        "page": 5
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "To compensate for the inbalance, we further curated more negative emotion dialogs so that the final set has equal emotion distributions. ",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.2979934640522876,
        "top": 0.2708787878787879,
        "width": 0.18521568627450974,
        "height": 0.012578282828282827,
        "page": 6
      },
      {
        "left": 0.08790522875816993,
        "top": 0.2859734848484849,
        "width": 0.39255555555555555,
        "height": 0.012578282828282827,
        "page": 6
      },
      {
        "left": 0.08790522875816993,
        "top": 0.3010681818181818,
        "width": 0.31526633986928104,
        "height": 0.012578282828282827,
        "page": 6
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "If the emotion embedding layer is learning and distinguishing affect states correctly, we will see clear differences in the visualization.",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.6928660130718954,
        "top": 0.7086313131313131,
        "width": 0.2192287581699346,
        "height": 0.012578282828282772,
        "page": 7
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7237260101010101,
        "width": 0.39256045751633983,
        "height": 0.012578282828282772,
        "page": 7
      },
      {
        "left": 0.5195343137254902,
        "top": 0.738820707070707,
        "width": 0.26798039215686276,
        "height": 0.012578282828282772,
        "page": 7
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "The comparison between perplexity scores and human evaluation results further confirms the fact that in the context",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.10418464052287582,
        "top": 0.8526805555555556,
        "width": 0.3762875816993464,
        "height": 0.012578282828282772,
        "page": 7
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8677752525252526,
        "width": 0.39256045751633994,
        "height": 0.012578282828282772,
        "page": 7
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Thus, in the future, we plan to train our model on the multi-turn conversations that we have already extracted from the much bigger OpenSubtitles corpus and the EmpatheticDialogues dataset. ",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.5777124183006536,
        "top": 0.5772058080808081,
        "width": 0.33437581699346397,
        "height": 0.012578282828282772,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.592300505050505,
        "width": 0.39256209150326793,
        "height": 0.012578282828282883,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.607395202020202,
        "width": 0.3953071895424838,
        "height": 0.012578282828282772,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.622489898989899,
        "width": 0.15855555555555545,
        "height": 0.012578282828282772,
        "page": 8
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "For future directions, we would like to investigate the diversity issue of the responses generated, possibly by extending the mutual information objective function [17] to multi-turn settings. ",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.5195343137254902,
        "top": 0.562969696969697,
        "width": 0.39531699346405236,
        "height": 0.012578282828282772,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5780643939393939,
        "width": 0.39256209150326793,
        "height": 0.012578282828282772,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5931603535353536,
        "width": 0.3925669934640523,
        "height": 0.012578282828282772,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6082550505050505,
        "width": 0.054500000000000104,
        "height": 0.012578282828282772,
        "page": 9
      }
    ],
    "section": "5 Conclusion and Future Work",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "As future work, we would like to adopt the Transformer architecture to replace the RNNs in our model, and initialize our encoder with pre-trained language models. ",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.28075980392156863,
        "top": 0.7490126262626262,
        "width": 0.19970098039215683,
        "height": 0.012578282828282772,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7641073232323232,
        "width": 0.39255882352941174,
        "height": 0.012578282828282772,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7792020202020202,
        "width": 0.3925604575163399,
        "height": 0.012578282828282772,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7942967171717171,
        "width": 0.11750816993464051,
        "height": 0.012578282828282772,
        "page": 9
      }
    ],
    "section": "5 Conclusion and Future Work",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "We believe reproducing conversational and emotional intelligence will make social chatbots more believable and engaging. In this paper, we proposed a multi-turn dialog system",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.08712418300653595,
        "top": 0.8595795454545455,
        "width": 0.39609967320261436,
        "height": 0.012578282828282772,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8746755050505051,
        "width": 0.3953039215686274,
        "height": 0.012578282828282772,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.889770202020202,
        "width": 0.3925604575163399,
        "height": 0.012578282828282772,
        "page": 9
      }
    ],
    "section": "5 Conclusion and Future Work",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "Automatic Evaluation Results. ",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.5195343137254902,
        "top": 0.5331287878787879,
        "width": 0.19815686274509803,
        "height": 0.012578282828282772,
        "page": 6
      }
    ],
    "section": "",
    "prob": 0.9091019034385681,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Human Evaluation Results. ",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.5195343137254902,
        "top": 0.6482638888888889,
        "width": 0.1775506535947713,
        "height": 0.012578282828282772,
        "page": 6
      }
    ],
    "section": "4 Evaluation 4.4 Results",
    "prob": 0.9075150489807129,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "We conducted t -test on the perplexity obtained, and results show significant improvements of MEED over S2S and HRAN on the two validation sets (with p -value < 0 . 05).",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.6071176470588235,
        "top": 0.5934949494949495,
        "width": 0.3067712418300653,
        "height": 0.012590909090908986,
        "page": 6
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6085896464646464,
        "width": 0.39256045751633983,
        "height": 0.012578282828282772,
        "page": 6
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6233459595959596,
        "width": 0.3950473856209151,
        "height": 0.012930555555555445,
        "page": 6
      }
    ],
    "section": "4 Evaluation 4.4 Results",
    "prob": 0.8971232175827026,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "We first conducted Friedman test [12] and then t -test on the human evaluation results (contextual coherence and emotional appropriateness), showing the improvements of MEED over S2S are significant (with p -value < 0 . 01).",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.17087254901960783,
        "top": 0.792300505050505,
        "width": 0.3095882352941176,
        "height": 0.012578282828282994,
        "page": 7
      },
      {
        "left": 0.08733660130718955,
        "top": 0.807395202020202,
        "width": 0.39312091503267976,
        "height": 0.012590909090909097,
        "page": 7
      },
      {
        "left": 0.08790522875816993,
        "top": 0.822489898989899,
        "width": 0.392562091503268,
        "height": 0.012578282828282772,
        "page": 7
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8372462121212122,
        "width": 0.3676045751633987,
        "height": 0.012930555555555445,
        "page": 7
      }
    ],
    "section": "",
    "prob": 0.8670583963394165,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "Figure 2 gives the results in three subplots. ",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.6534477124183007,
        "top": 0.8444848484848485,
        "width": 0.26140196078431377,
        "height": 0.012578282828282772,
        "page": 7
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8595795454545455,
        "width": 0.035303921568627494,
        "height": 0.012578282828282772,
        "page": 7
      }
    ],
    "section": "",
    "prob": 0.8245140910148621,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "The main objective of the emotion embedding layer is to recognize the affect information in the given utterances so that the model can respond with emotionally appropriate replies. ",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.5190457516339869,
        "top": 0.6935366161616161,
        "width": 0.39304084967320263,
        "height": 0.012578282828282994,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7086313131313131,
        "width": 0.39256209150326793,
        "height": 0.012578282828282772,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7237260101010101,
        "width": 0.39256045751633983,
        "height": 0.012578282828282772,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.738820707070707,
        "width": 0.046616013071895446,
        "height": 0.012578282828282772,
        "page": 3
      }
    ],
    "section": "",
    "prob": 0.9020901918411255,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Most of related work focused on integrating affect information into the transduction vector space using either VAD or LIWC, we aim at modeling and generating the affect exchanges in human dialogs using a dedicated embedding layer. ",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.19458496732026143,
        "top": 0.7237260101010101,
        "width": 0.2858807189542484,
        "height": 0.012578282828282772,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.738820707070707,
        "width": 0.392562091503268,
        "height": 0.012578282828282772,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.753915404040404,
        "width": 0.3925604575163399,
        "height": 0.012578282828282772,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.769010101010101,
        "width": 0.3953039215686274,
        "height": 0.012578282828282772,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7841060606060606,
        "width": 0.09316013071895425,
        "height": 0.012578282828282994,
        "page": 2
      }
    ],
    "section": "2 Related Work",
    "prob": 0.895667314529419,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "Our main goal is to increase the objectivity of the results and reduce judges mistakes due to out-of-context dialogs they have to evaluate.",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.08790522875816993,
        "top": 0.8595795454545455,
        "width": 0.3925604575163399,
        "height": 0.012578282828282772,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8746755050505051,
        "width": 0.39298202614379085,
        "height": 0.012578282828282772,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.889770202020202,
        "width": 0.11183496732026145,
        "height": 0.012578282828282772,
        "page": 1
      }
    ],
    "section": "1 Introduction",
    "prob": 0.829452633857727,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "In this paper, we describe an end-to-end Multi-turn Emotionally Engaging Dialog model (MEED), capable of recognizing emotions and generating emotionally appropriate and humanlike responses with the ultimate goal of reproducing social behaviors that are habitual in human-human conversations. ",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.46679738562091505,
        "top": 0.3161628787878788,
        "width": 0.013671568627451003,
        "height": 0.012578282828282827,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.3312588383838384,
        "width": 0.3929901960784314,
        "height": 0.012578282828282827,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.34635353535353536,
        "width": 0.3953039215686275,
        "height": 0.012578282828282827,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.3614482323232323,
        "width": 0.3953153594771242,
        "height": 0.012578282828282827,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.37654292929292926,
        "width": 0.39255882352941174,
        "height": 0.012578282828282883,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.39163762626262627,
        "width": 0.39506862745098037,
        "height": 0.012578282828282827,
        "page": 1
      }
    ],
    "section": "",
    "prob": 0.76461261510849,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "The main idea is to use an internal memory module to capture the emotion dynamics during decoding, and an external memory module to model emotional expressions explicitly by assigning different probability values to emotional words as opposed to regular words. ",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.08741666666666667,
        "top": 0.3614482323232323,
        "width": 0.39580228758169933,
        "height": 0.012578282828282827,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.37654292929292926,
        "width": 0.3925604575163399,
        "height": 0.012578282828282883,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.39163762626262627,
        "width": 0.3929901960784314,
        "height": 0.012578282828282827,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.4067323232323232,
        "width": 0.3925604575163399,
        "height": 0.012578282828282827,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.42182828282828283,
        "width": 0.1886274509803922,
        "height": 0.012578282828282827,
        "page": 2
      }
    ],
    "section": "2 Related Work",
    "prob": 0.6889792680740356,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Specifically, we randomly shuffled the 100 dialogs in the test set, then we used the first three utterances of each dialog as the input to the three models being compared (S2S, HRAN, and MEED), and obtain the respective responses. ",
    "label": "Method",
    "bboxes": [
      {
        "left": 0.8640081699346406,
        "top": 0.1350239898989899,
        "width": 0.050841503267973875,
        "height": 0.012578282828282827,
        "page": 6
      },
      {
        "left": 0.5195343137254902,
        "top": 0.1501199494949495,
        "width": 0.3943529411764706,
        "height": 0.012578282828282827,
        "page": 6
      },
      {
        "left": 0.5195343137254902,
        "top": 0.16521464646464645,
        "width": 0.39256209150326793,
        "height": 0.012578282828282855,
        "page": 6
      },
      {
        "left": 0.5195343137254902,
        "top": 0.18030934343434343,
        "width": 0.39255392156862745,
        "height": 0.012578282828282827,
        "page": 6
      },
      {
        "left": 0.5195343137254902,
        "top": 0.19540404040404039,
        "width": 0.2876683006535947,
        "height": 0.012578282828282855,
        "page": 6
      }
    ],
    "section": "4.3.1 Human evaluation setup",
    "prob": 0.6610681414604187,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "Additionally, we extract the emotion information from the utterances in X by leveraging an external text analysis program, and use an RNN to encode it into an emotion context vector e , which is combined with c t to produce the distribution. ",
    "label": "Method",
    "bboxes": [
      {
        "left": 0.8517271241830064,
        "top": 0.5072512626262626,
        "width": 0.06311274509803921,
        "height": 0.012578282828282772,
        "page": 2
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5223459595959595,
        "width": 0.39256045751633983,
        "height": 0.012578282828282883,
        "page": 2
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5374027777777778,
        "width": 0.392563725490196,
        "height": 0.012616161616161525,
        "page": 2
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5524974747474747,
        "width": 0.3943513071895425,
        "height": 0.012616161616161636,
        "page": 2
      },
      {
        "left": 0.5189330065359476,
        "top": 0.5675921717171717,
        "width": 0.363326797385621,
        "height": 0.013718434343434449,
        "page": 2
      }
    ],
    "section": "3 Model",
    "prob": 0.6390365958213806,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "decoding phase, Equation (16) takes o t , the concatenation of the language context vector s t and the emotion context vector e , and generates a probability distribution over the vocabulary words by applying a softmax layer. ",
    "label": "Method",
    "bboxes": [
      {
        "left": 0.5775,
        "top": 0.49726388888888895,
        "width": 0.33734477124182993,
        "height": 0.013718434343434227,
        "page": 7
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5123598484848485,
        "width": 0.3925669934640523,
        "height": 0.013717171717171683,
        "page": 7
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5274545454545455,
        "width": 0.39255882352941174,
        "height": 0.012616161616161525,
        "page": 7
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5425871212121212,
        "width": 0.36316503267973854,
        "height": 0.012578282828282772,
        "page": 7
      }
    ],
    "section": "",
    "prob": 0.5452488660812378,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Specifically, a tone indicator is added to each step of the decoder during the training phase.",
    "label": "Method",
    "bboxes": [
      {
        "left": 0.2748039215686275,
        "top": 0.5274924242424243,
        "width": 0.20566176470588238,
        "height": 0.012578282828282772,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.5425871212121212,
        "width": 0.39500163398692806,
        "height": 0.012578282828282772,
        "page": 2
      }
    ],
    "section": "",
    "prob": 0.5112543106079102,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "To extract the affect information contained in the utterances, we used the LIWC text analysis program. ",
    "label": "Method",
    "bboxes": [
      {
        "left": 0.08741666666666667,
        "top": 0.769010101010101,
        "width": 0.39484150326797385,
        "height": 0.012578282828282772,
        "page": 8
      },
      {
        "left": 0.08730392156862746,
        "top": 0.7841060606060606,
        "width": 0.28403431372549015,
        "height": 0.012578282828282994,
        "page": 8
      }
    ],
    "section": "",
    "prob": 0.5109821557998657,
    "is_author_statement": true,
    "is_in_expected_section": false
  }
]